{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up API Key for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Diversity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdiversity.measures import ShannonEntropyMeasure\n",
    "diversity_measure = ShannonEntropyMeasure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdiversity.models import OpenAIModel\n",
    "from langdiversity.parser import extract_last_letters\n",
    "TEMPERATURE = 0.8\n",
    "model = OpenAIModel(openai_api_key=openai_api_key, extractor=extract_last_letters, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Diversity Measure Calculator Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdiversity.utils import DiversityMeasureCollector\n",
    "diversity_collector = DiversityMeasureCollector(model=model, num_responses=10, diversity_measure=diversity_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Few-Shot Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_question = \"\\nAt the end, say 'the answer is [put the concatenated word here]'.\\nQuestion: Take the last letter of each word in \\\"Tal Evan Lesley Sidney\\\" and concatenate them..\"\n",
    "\n",
    "fewshot_prompts = [\n",
    "    f\"\\nPrompt 1:\\nExample 1: Concatenate the last letters of 'Hello World' -> 'od'\\nExample 2: Concatenate the last letters of 'Python Ruby Sapphire' -> 'nye'\\nExample 3: Concatenate the last letters of 'Learning Teaching Assistant' -> 'ggt'\\nExample 4: Concatenate the last letters of 'Reading Writing Center' -> 'ggr'\\nExample 5: Concatenate the last letters of 'Singing Dancing Person' -> 'ggn'{original_question}\",\n",
    "    f\"\\nPrompt 2:\\nExample 1: Get the last letters of 'Innovation Creation' and concatenate them -> 'nn'\\nExample 2: Get the last letters of 'Motivation Dedications' and concatenate them -> 'ns'\\nExample 3: Get the last letters of 'Education Solute' and concatenate them -> 'ne'\\nExample 4: Get the last letters of 'Integration Pizza' and concatenate them -> 'na'\\nExample 5: Get the last letters of 'Inspiration Aspire' and concatenate them -> 'ne'{original_question}\",\n",
    "    f\"\\nPrompt 3:\\nExample 1: For 'Dance Sing', the last letters when concatenated form -> 'eg'\\nExample 2: For 'Jump School', the last letters when concatenated form -> 'pl'\\nExample 3: For 'Run Walk', the last letters when concatenated form -> 'nk'\\nExample 4: For 'Hop Jam', the last letters when concatenated form -> 'pm'\\nExample 5: For 'Sit Stand', the last letters when concatenated form -> 'td'{original_question}\",\n",
    "    f\"\\nPrompt 4:\\nExample 1: From 'Cake Bake', the concatenated last letters are -> 'ee'\\nExample 2: From 'Drive Ride', the concatenated last letters are -> 'ee'\\nExample 3: From 'Love Live', the concatenated last letters are -> 'ee'\\nExample 4: From 'Give Take', the concatenated last letters are -> 'ee'\\nExample 5: From 'Make Bake', the concatenated last letters are -> 'ee'{original_question}\",\n",
    "    f\"\\nPrompt 5:\\nExample 1: 'Read Write Dogma Deed' ends in -> 'dead'\\nExample 2: 'Play Stay Game Bin' ends in -> 'yyen'\\nExample 3: 'Dream Scream Deem Scheme' ends in -> 'mmme'\\nExample 4: 'Teach Reach Hands Sky' ends in -> 'hhsy'\\nExample 5: 'Learn Earn Pay Gap' ends in -> 'nnyp'{original_question}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass the questions to the Language Model, perform calculation based on the diversity of its responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] Collecting 10 responses... |"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] Collecting 10 responses... ✓\n",
      "[1/5] Performing diversity measure calculations... ✓\n",
      "Responses: lnyy, lnyy, lnyy, lnyy, lnyy, lndy, lnyy, lnyy, ylne, lnyy\n",
      "Diversity Measure (ShannonEntropyMeasure): 0.9219280948873623\n",
      "[2/5] Collecting 10 responses... ✓\n",
      "[2/5] Performing diversity measure calculations... ✓\n",
      "Responses: lnyy, lnyy, lnyy, lne, lnyy, lne, lnyy, lnyy, lnyy, lnyy\n",
      "Diversity Measure (ShannonEntropyMeasure): 0.7219280948873623\n",
      "[3/5] Collecting 10 responses... ✓\n",
      "[3/5] Performing diversity measure calculations... ✓\n",
      "Responses: lyn, lnyy, lyn, lnyd, leyn, lnyy, lnyy, lnevye, , lney\n",
      "Diversity Measure (ShannonEntropyMeasure): 2.6464393446710153\n",
      "[4/5] Collecting 10 responses... ✓\n",
      "[4/5] Performing diversity measure calculations... ✓\n",
      "Responses: lne, lndy, lne, lnyy, lnyy, lnyy, lnyy, lly, llny, lnyd\n",
      "Diversity Measure (ShannonEntropyMeasure): 2.321928094887362\n",
      "[5/5] Collecting 10 responses... ✓\n",
      "[5/5] Performing diversity measure calculations... ✓\n",
      "Responses: lnyy, lney, lnyy, lnyy, lndy, lnds, lnevye, lnevysy, lney, lndy\n",
      "Diversity Measure (ShannonEntropyMeasure): 2.4464393446710155\n"
     ]
    }
   ],
   "source": [
    "diversity_collector.collect(fewshot_prompts, verbose=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of Failure vs Diversity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Probability of Failure</th>\n",
       "      <th>Diversity Score</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1</td>\n",
       "      <td>[lnyy, lnyy, lnyy, lnyy, lnyy, lndy, lnyy, lny...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.921928</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2</td>\n",
       "      <td>[lnyy, lnyy, lnyy, lne, lnyy, lne, lnyy, lnyy,...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt 3</td>\n",
       "      <td>[lyn, lnyy, lyn, lnyd, leyn, lnyy, lnyy, lnevy...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.646439</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt 4</td>\n",
       "      <td>[lne, lndy, lne, lnyy, lnyy, lnyy, lnyy, lly, ...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt 5</td>\n",
       "      <td>[lnyy, lney, lnyy, lnyy, lndy, lnds, lnevye, l...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.446439</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prompt                                          Responses  \\\n",
       "0  Prompt 1  [lnyy, lnyy, lnyy, lnyy, lnyy, lndy, lnyy, lny...   \n",
       "1  Prompt 2  [lnyy, lnyy, lnyy, lne, lnyy, lne, lnyy, lnyy,...   \n",
       "2  Prompt 3  [lyn, lnyy, lyn, lnyd, leyn, lnyy, lnyy, lnevy...   \n",
       "3  Prompt 4  [lne, lndy, lne, lnyy, lnyy, lnyy, lnyy, lly, ...   \n",
       "4  Prompt 5  [lnyy, lney, lnyy, lnyy, lndy, lnds, lnevye, l...   \n",
       "\n",
       "   Probability of Failure  Diversity Score  Temperature  \n",
       "0                     0.2         0.921928          0.8  \n",
       "1                     0.2         0.721928          0.8  \n",
       "2                     0.7         2.646439          0.8  \n",
       "3                     0.6         2.321928          0.8  \n",
       "4                     0.7         2.446439          0.8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Prompt\": [f\"Prompt {i+1}\" for i in range(len(diversity_collector.data))],\n",
    "    \"Responses\": [item['responses'] for item in diversity_collector.data],\n",
    "    \"Probability of Failure\": [\n",
    "        (len(item['responses']) - item['responses'].count('lnyy')) / len(item['responses']) \n",
    "        for item in diversity_collector.data\n",
    "    ],\n",
    "    \"Diversity Score\": [item['diversity'] for item in diversity_collector.data],\n",
    "    \"Temperature\": TEMPERATURE\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Prompt Selection Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdiversity.utils import PromptSelection\n",
    "filter = PromptSelection(data=diversity_collector.data, selection=\"min\")\n",
    "prompts = filter.select()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Prompt with the Minimum Diversity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Selected Prompt</th>\n",
       "      <th>Diversity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.721928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Selected Prompt  Diversity Score\n",
       "0               2         0.721928"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "prompt_results = {\n",
    "    \"Selected Prompt\": [re.search(r\"Prompt (\\d+):\", prompt).group(1) for prompt in prompts['selected_prompts']],\n",
    "    \"Diversity Score\": [prompts['diversity']] * len(prompts['selected_prompts']),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(prompt_results)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
